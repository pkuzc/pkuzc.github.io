---
title: "Sparse DNNs with Improved Adversarial Robustness"
collection: publications
permalink: /publications/nips2018
venue: "NIPS 2018"
date: 2018-12-09

citation: 'Yiwen Guo, <b>Chao Zhang<\b>(equal contribution), Changshui Zhang, Yurong Chen. <i>The Thirty-second Annual Conference on Neural Information Processing Systems<\i>. <b>NIPS 2018<\b>.'
---

[[PDF]](https://pkuzc.github.io/files/nips_2018_camera.pdf)

## Abstract

As aggregators, online news portals face great challenges in continuously selecting a pool of candidate. Deep neural networks (DNNs) are computationally/memory-intensive and vulnerable to adversarial attacks, making them prohibitive in some real-world applications. By converting dense models into sparse ones, pruning appears to be a promising solution to reducing the computation/memory cost. This paper studies classification models, especially DNN-based ones, to demonstrate that there exists intrinsic relationships between their sparsity and adversarial robustness. Our analyses reveal, both theoretically and empirically, that nonlinear DNN-based classifiers behave differently under l2 attacks from some linear ones. We further demonstrate that an appropriately higher model sparsity implies better robustness of nonlinear DNNs, whereas over-sparsified models can be more difficult to resist adversarial examples.

